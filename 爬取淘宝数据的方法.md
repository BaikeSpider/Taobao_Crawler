# 收费方法：
[淘宝开放平台](http://open.taobao.com/doc2/apiList.htm?cid=6&docType=)中，提供了众多免费和收费接口，比如搜索评价信息的收费API

`taobao.traderates.get`

# 免费方法：
利用爬虫爬取目标数据。

假设我们需要爬取淘宝上空调的销售情况，以便做出买/卖决定，我们可以爬取"空调"搜索页面，顺着"品牌"区域，分别爬取各品牌不同型号空调的

A品牌B型号C匹数D价格E卖家数 等，以供下一步分析。

## 方法一: 模拟真人使用浏览器行为(taobao_1目录)(停止开发)
淘宝的搜索结果页面使用一种独特的加载数据的方式，既不是直接的HTML，也不是通过请求JSON数据，而是把数据放在JavaScript代码里面。

使用Scrapy调度请求，parse response，使用浏览器自动工具Selenium加载和渲染页面。

优点: 模仿人类行为，不容易被反爬虫发现，页面经过JS渲染，符合人眼看到的效果，结合浏览器插件功能更强大。

取点: 需要浏览器(也可以是headless的PhantomJS)访问页面，速度慢，渲染过程中发起请求较多，占用内存较大。

## 方法二: 解析淘宝返回的JS代码(taobao_2目录)(推荐)
仅使用开源爬虫Scrapy, 直接解析响应, 但是此处不需要使用HTML解析工具如BeautifulSoup等, 因为最重要的数据放在JavaScript代码中一个叫做g_page_config的变量当中, 提取此Object即可.

优点: 爬取量很少，不需要渲染，速度快

缺点: 爬取太频繁，只抓取单一页面(不加载图片，CSS，JS等)，容易被反爬虫怀疑，强制验证。

## 困难:
如果想要爬虫通过淘宝的人类验证，是非常困难的:

如果不登录，查看几个页面之后，就会被要求登录。

如果在发送的请求中加载已登录的cookie，如果请求发送太频繁，还是会被强制验证。

既然无法通过淘宝的人类验证，干脆绕着走，直接禁用cookie，不让频繁发送请求，就降低发送频率，每次换一个User-Agent(只看UA，服务器会认为是一个网关后面的不同浏览器发出的请求)，使用代理伪装IP(甚至有云爬虫)，用了这些手段之后，如果还是遇到了强制验证，那就停止所有请求，过一会继续retry。

这样，基本上就可以顺利的爬取到数据了。

# 躲避反爬虫的一般方法:
* 使用随机User-Agent
* [禁用Cookie](http://doc.scrapy.org/en/latest/topics/practices.html#avoiding-getting-banned)
* 请求限流，限制同时请求数，设置请求间隔
* 不要只请求所需页面，适当加载其他资源(图片，CSS，JS等)
* 使用代理，把请求均匀分布到不同的代理服务器上
* [云爬虫](http://scrapinghub.com/crawlera/)

# 参考
早期推荐模仿[关于“淘宝爆款”的数据抓取与数据分析](http://blog.csdn.net/u012150179/article/details/37306629)

[Scrapy - Avoiding getting banned](http://doc.scrapy.org/en/latest/topics/practices.html#avoiding-getting-banned)